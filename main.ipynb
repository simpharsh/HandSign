{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "bc24951f",
      "metadata": {
        "id": "bc24951f"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "e_XamV7yjVs3",
        "outputId": "df78aeed-de56-4803-a6cf-31419d15a75b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "e_XamV7yjVs3",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "ZIP_PATH = \"/content/drive/MyDrive/archive.zip\"  # <-- CHANGE if needed\n",
        "EXTRACT_PATH = \"/content/asl_dataset\"\n",
        "\n",
        "os.makedirs(EXTRACT_PATH, exist_ok=True)\n",
        "\n",
        "with zipfile.ZipFile(ZIP_PATH, 'r') as zip_ref:\n",
        "    zip_ref.extractall(EXTRACT_PATH)\n",
        "\n",
        "print(\"Extracted to:\", EXTRACT_PATH)\n",
        "print(\"Folders:\", os.listdir(EXTRACT_PATH))\n"
      ],
      "metadata": {
        "id": "dJX4EO74jkjs",
        "outputId": "04b67de6-2800-4aa0-9be3-0282bfd1476c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "dJX4EO74jkjs",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted to: /content/asl_dataset\n",
            "Folders: ['asl_alphabet_train', 'asl_alphabet_test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = f\"{EXTRACT_PATH}/asl_alphabet_train\"\n",
        "TEST_DIR = f\"{EXTRACT_PATH}/asl_alphabet_test\"\n"
      ],
      "metadata": {
        "id": "-u2JRDF0j1xA"
      },
      "id": "-u2JRDF0j1xA",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(\"Train exists?\", os.path.exists(TRAIN_DIR))\n",
        "print(\"Train folders:\", os.listdir(TRAIN_DIR))\n",
        "print(\"-\" * 50)\n",
        "print(\"Test exists?\", os.path.exists(TEST_DIR))\n",
        "print(\"Test folders:\", os.listdir(TEST_DIR))\n"
      ],
      "metadata": {
        "id": "sko0tChAj7VR",
        "outputId": "d0fcd11b-8295-41a3-cae7-751078a279d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "sko0tChAj7VR",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train exists? True\n",
            "Train folders: ['asl_alphabet_train']\n",
            "--------------------------------------------------\n",
            "Test exists? True\n",
            "Test folders: ['asl_alphabet_test']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "0473eb1e",
      "metadata": {
        "id": "0473eb1e"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Imports (run this first)\n",
        "\n",
        "import os\n",
        "import time\n",
        "import numpy as np\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "print(\"TF version:\", tf.__version__)\n",
        "print(\"GPUs:\", tf.config.list_physical_devices('GPU'))\n"
      ],
      "metadata": {
        "id": "O9oScRRNaz0V",
        "outputId": "00fb7adb-de20-4bf1-8668-a37623746cc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "O9oScRRNaz0V",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TF version: 2.19.0\n",
            "GPUs: [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "7e695f4a",
      "metadata": {
        "id": "7e695f4a",
        "outputId": "e072e5a1-dacf-4942-a993-ab83d8adf57e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN_DIR: /content/asl_dataset/asl_alphabet_train/asl_alphabet_train\n",
            "Exists? True\n",
            "Sample contents: ['J', 'V', 'G', 'H', 'M', 'B', 'L', 'X', 'space', 'U', 'E', 'A', 'S', 'P', 'D', 'O', 'Y', 'del', 'I', 'Z']\n",
            "Number of classes: 29\n",
            "Classes: ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'Space', 'Del', 'Nothing']\n"
          ]
        }
      ],
      "source": [
        "# Cell 2: Configuration (UPDATED)\n",
        "\n",
        "import os\n",
        "\n",
        "TRAIN_DIR = \"/content/asl_dataset/asl_alphabet_train/asl_alphabet_train\"\n",
        "print(\"TRAIN_DIR:\", TRAIN_DIR)\n",
        "print(\"Exists?\", os.path.exists(TRAIN_DIR))\n",
        "\n",
        "# Peek inside to see what’s there\n",
        "print(\"Sample contents:\", os.listdir(TRAIN_DIR)[:20])\n",
        "\n",
        "IMG_HEIGHT = 200\n",
        "IMG_WIDTH = 200\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 20\n",
        "\n",
        "# Our target classes\n",
        "CLASSES = list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\") + [\"Space\", \"Del\", \"Nothing\"]\n",
        "\n",
        "print(\"Number of classes:\", len(CLASSES))\n",
        "print(\"Classes:\", CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: Create train & validation generators\n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1.0/255.0,\n",
        "    validation_split=0.2,\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\"\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"training\",\n",
        "    shuffle=True,\n",
        "    classes=CLASSES  # force class order\n",
        ")\n",
        "\n",
        "val_generator = datagen.flow_from_directory(\n",
        "    TRAIN_DIR,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    subset=\"validation\",\n",
        "    shuffle=False,\n",
        "    classes=CLASSES\n",
        ")\n"
      ],
      "metadata": {
        "id": "pqKSdNIAkOol",
        "outputId": "d0d73933-1300-4513-f105-bcc144d7304b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "pqKSdNIAkOol",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 62400 images belonging to 29 classes.\n",
            "Found 15600 images belonging to 29 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: Define an improved CNN model with BatchNorm & Dropout\n",
        "\n",
        "num_classes = train_generator.num_classes   # should be 29\n",
        "print(\"Number of classes in generator:\", num_classes)\n",
        "\n",
        "from tensorflow.keras import layers, models\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.Input(shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
        "\n",
        "    # Block 1\n",
        "    layers.Conv2D(32, (3, 3), padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 2\n",
        "    layers.Conv2D(64, (3, 3), padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 3\n",
        "    layers.Conv2D(128, (3, 3), padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    # Block 4 (light)\n",
        "    layers.Conv2D(256, (3, 3), padding=\"same\"),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(512),\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Activation(\"relu\"),\n",
        "    layers.Dropout(0.5),\n",
        "\n",
        "    layers.Dense(num_classes, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "# If mixed precision is enabled, optimizer will handle scaling\n",
        "opt = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "\n",
        "model.compile(\n",
        "    optimizer=opt,\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "1uNcG3RWkaqu",
        "outputId": "8eca90ae-9737-4ec9-dbc4-76e09f499aa3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "id": "1uNcG3RWkaqu",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of classes in generator: 29\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m896\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │           \u001b[38;5;34m128\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m200\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m32\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m18,496\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │        \u001b[38;5;34m73,856\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │           \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m50\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_8 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m25\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m36864\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │    \u001b[38;5;34m18,874,880\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_9 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m29\u001b[0m)             │        \u001b[38;5;34m14,877\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">50</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">25</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ max_pooling2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">36864</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │    <span style=\"color: #00af00; text-decoration-color: #00af00\">18,874,880</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ activation_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">29</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">14,877</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m19,282,141\u001b[0m (73.56 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,282,141</span> (73.56 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m19,280,157\u001b[0m (73.55 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">19,280,157</span> (73.55 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,984\u001b[0m (7.75 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,984</span> (7.75 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 5: Train the model with callbacks (best model selection)\n",
        "\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "\n",
        "BEST_MODEL_PATH = \"asl_best_model.h5\"\n",
        "\n",
        "checkpoint_cb = ModelCheckpoint(\n",
        "    BEST_MODEL_PATH,\n",
        "    monitor=\"val_accuracy\",\n",
        "    mode=\"max\",\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "earlystop_cb = EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    patience=5,          # stop if no improvement for 5 epochs\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "reducelr_cb = ReduceLROnPlateau(\n",
        "    monitor=\"val_loss\",\n",
        "    factor=0.3,\n",
        "    patience=3,          # after 3 bad epochs → reduce LR\n",
        "    min_lr=1e-6,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "steps_per_epoch = train_generator.samples // BATCH_SIZE\n",
        "validation_steps = val_generator.samples // BATCH_SIZE\n",
        "\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    epochs=EPOCHS,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_data=val_generator,\n",
        "    validation_steps=validation_steps,\n",
        "    callbacks=[checkpoint_cb, earlystop_cb, reducelr_cb]\n",
        ")\n"
      ],
      "metadata": {
        "id": "j77Q4xPXl9oH",
        "outputId": "3cc81f55-5f69-4c66-9742-ad755bab2bcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "j77Q4xPXl9oH",
      "execution_count": 14,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.4294 - loss: 1.9314\n",
            "Epoch 1: val_accuracy improved from -inf to 0.57713, saving model to asl_best_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m796s\u001b[0m 404ms/step - accuracy: 0.4295 - loss: 1.9310 - val_accuracy: 0.5771 - val_loss: 1.4167 - learning_rate: 0.0010\n",
            "Epoch 2/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.8557 - loss: 0.4264\n",
            "Epoch 2: val_accuracy did not improve from 0.57713\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m784s\u001b[0m 402ms/step - accuracy: 0.8557 - loss: 0.4263 - val_accuracy: 0.5061 - val_loss: 1.9561 - learning_rate: 0.0010\n",
            "Epoch 3/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 329ms/step - accuracy: 0.9171 - loss: 0.2423\n",
            "Epoch 3: val_accuracy did not improve from 0.57713\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 404ms/step - accuracy: 0.9171 - loss: 0.2423 - val_accuracy: 0.4587 - val_loss: 2.8449 - learning_rate: 0.0010\n",
            "Epoch 4/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 332ms/step - accuracy: 0.9472 - loss: 0.1551\n",
            "Epoch 4: val_accuracy improved from 0.57713 to 0.79286, saving model to asl_best_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 406ms/step - accuracy: 0.9472 - loss: 0.1551 - val_accuracy: 0.7929 - val_loss: 0.6733 - learning_rate: 0.0010\n",
            "Epoch 5/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9587 - loss: 0.1194\n",
            "Epoch 5: val_accuracy did not improve from 0.79286\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m778s\u001b[0m 399ms/step - accuracy: 0.9587 - loss: 0.1194 - val_accuracy: 0.7306 - val_loss: 0.8971 - learning_rate: 0.0010\n",
            "Epoch 6/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 326ms/step - accuracy: 0.9668 - loss: 0.0997\n",
            "Epoch 6: val_accuracy did not improve from 0.79286\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m802s\u001b[0m 399ms/step - accuracy: 0.9668 - loss: 0.0997 - val_accuracy: 0.7153 - val_loss: 1.0619 - learning_rate: 0.0010\n",
            "Epoch 7/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9706 - loss: 0.0853\n",
            "Epoch 7: val_accuracy improved from 0.79286 to 0.80794, saving model to asl_best_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 0.0003000000142492354.\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m773s\u001b[0m 396ms/step - accuracy: 0.9706 - loss: 0.0853 - val_accuracy: 0.8079 - val_loss: 0.7962 - learning_rate: 0.0010\n",
            "Epoch 8/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9860 - loss: 0.0420\n",
            "Epoch 8: val_accuracy improved from 0.80794 to 0.85511, saving model to asl_best_model.h5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m807s\u001b[0m 399ms/step - accuracy: 0.9860 - loss: 0.0420 - val_accuracy: 0.8551 - val_loss: 0.6480 - learning_rate: 3.0000e-04\n",
            "Epoch 9/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.9917 - loss: 0.0260\n",
            "Epoch 9: val_accuracy did not improve from 0.85511\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m782s\u001b[0m 401ms/step - accuracy: 0.9917 - loss: 0.0260 - val_accuracy: 0.8309 - val_loss: 0.7065 - learning_rate: 3.0000e-04\n",
            "Epoch 10/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.9926 - loss: 0.0230\n",
            "Epoch 10: val_accuracy improved from 0.85511 to 0.86531, saving model to asl_best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m779s\u001b[0m 400ms/step - accuracy: 0.9926 - loss: 0.0230 - val_accuracy: 0.8653 - val_loss: 0.6768 - learning_rate: 3.0000e-04\n",
            "Epoch 11/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9942 - loss: 0.0183\n",
            "Epoch 11: val_accuracy did not improve from 0.86531\n",
            "\n",
            "Epoch 11: ReduceLROnPlateau reducing learning rate to 9.000000427477062e-05.\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m785s\u001b[0m 402ms/step - accuracy: 0.9942 - loss: 0.0183 - val_accuracy: 0.8592 - val_loss: 0.6525 - learning_rate: 3.0000e-04\n",
            "Epoch 12/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 331ms/step - accuracy: 0.9948 - loss: 0.0157\n",
            "Epoch 12: val_accuracy did not improve from 0.86531\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m791s\u001b[0m 405ms/step - accuracy: 0.9948 - loss: 0.0157 - val_accuracy: 0.8649 - val_loss: 0.6686 - learning_rate: 9.0000e-05\n",
            "Epoch 13/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 322ms/step - accuracy: 0.9961 - loss: 0.0118\n",
            "Epoch 13: val_accuracy improved from 0.86531 to 0.87423, saving model to asl_best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m771s\u001b[0m 395ms/step - accuracy: 0.9961 - loss: 0.0118 - val_accuracy: 0.8742 - val_loss: 0.6478 - learning_rate: 9.0000e-05\n",
            "Epoch 14/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 319ms/step - accuracy: 0.9963 - loss: 0.0116\n",
            "Epoch 14: val_accuracy did not improve from 0.87423\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m793s\u001b[0m 391ms/step - accuracy: 0.9963 - loss: 0.0116 - val_accuracy: 0.8699 - val_loss: 0.6658 - learning_rate: 9.0000e-05\n",
            "Epoch 15/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9970 - loss: 0.0098\n",
            "Epoch 15: val_accuracy did not improve from 0.87423\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m769s\u001b[0m 394ms/step - accuracy: 0.9970 - loss: 0.0098 - val_accuracy: 0.8727 - val_loss: 0.5963 - learning_rate: 9.0000e-05\n",
            "Epoch 16/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 327ms/step - accuracy: 0.9968 - loss: 0.0094\n",
            "Epoch 16: val_accuracy improved from 0.87423 to 0.87699, saving model to asl_best_model.h5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m779s\u001b[0m 400ms/step - accuracy: 0.9968 - loss: 0.0094 - val_accuracy: 0.8770 - val_loss: 0.6293 - learning_rate: 9.0000e-05\n",
            "Epoch 17/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 321ms/step - accuracy: 0.9975 - loss: 0.0085\n",
            "Epoch 17: val_accuracy did not improve from 0.87699\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m770s\u001b[0m 395ms/step - accuracy: 0.9975 - loss: 0.0085 - val_accuracy: 0.8733 - val_loss: 0.6300 - learning_rate: 9.0000e-05\n",
            "Epoch 18/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330ms/step - accuracy: 0.9975 - loss: 0.0081\n",
            "Epoch 18: val_accuracy did not improve from 0.87699\n",
            "\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 2.700000040931627e-05.\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m788s\u001b[0m 404ms/step - accuracy: 0.9975 - loss: 0.0081 - val_accuracy: 0.8696 - val_loss: 0.7209 - learning_rate: 9.0000e-05\n",
            "Epoch 19/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step - accuracy: 0.9980 - loss: 0.0067\n",
            "Epoch 19: val_accuracy did not improve from 0.87699\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m779s\u001b[0m 399ms/step - accuracy: 0.9980 - loss: 0.0067 - val_accuracy: 0.8731 - val_loss: 0.6754 - learning_rate: 2.7000e-05\n",
            "Epoch 20/20\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 328ms/step - accuracy: 0.9983 - loss: 0.0055\n",
            "Epoch 20: val_accuracy did not improve from 0.87699\n",
            "\u001b[1m1950/1950\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m783s\u001b[0m 401ms/step - accuracy: 0.9983 - loss: 0.0055 - val_accuracy: 0.8761 - val_loss: 0.6531 - learning_rate: 2.7000e-05\n",
            "Epoch 20: early stopping\n",
            "Restoring model weights from the end of the best epoch: 15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: Save class indices (model already saved via checkpoint)\n",
        "\n",
        "CLASS_INDICES_PATH = \"asl_class_indices.npy\"\n",
        "\n",
        "np.save(CLASS_INDICES_PATH, train_generator.class_indices)\n",
        "\n",
        "print(\"✅ Saved best model to:\", BEST_MODEL_PATH)\n",
        "print(\"✅ Saved class indices to:\", CLASS_INDICES_PATH)\n",
        "print(\"Class indices:\", train_generator.class_indices)\n"
      ],
      "metadata": {
        "id": "IB0oXUpUmFt-",
        "outputId": "39489efe-cf50-40ec-87b6-333231ef1d82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "IB0oXUpUmFt-",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Saved best model to: asl_best_model.h5\n",
            "✅ Saved class indices to: asl_class_indices.npy\n",
            "Class indices: {'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'I': 8, 'J': 9, 'K': 10, 'L': 11, 'M': 12, 'N': 13, 'O': 14, 'P': 15, 'Q': 16, 'R': 17, 'S': 18, 'T': 19, 'U': 20, 'V': 21, 'W': 22, 'X': 23, 'Y': 24, 'Z': 25, 'Space': 26, 'Del': 27, 'Nothing': 28}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: Load BEST model + class mapping & evaluate\n",
        "\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "BEST_MODEL_PATH = \"asl_best_model.h5\"\n",
        "CLASS_INDICES_PATH = \"asl_class_indices.npy\"\n",
        "\n",
        "model = keras.models.load_model(BEST_MODEL_PATH)\n",
        "class_indices = np.load(CLASS_INDICES_PATH, allow_pickle=True).item()\n",
        "\n",
        "index_to_class = {v: k for k, v in class_indices.items()}\n",
        "\n",
        "print(\"✅ Loaded best model from:\", BEST_MODEL_PATH)\n",
        "print(\"Classes (index_to_class):\", index_to_class)\n",
        "\n",
        "# Quick evaluation on validation set\n",
        "val_loss, val_acc = model.evaluate(val_generator, verbose=1)\n",
        "print(f\"Validation loss: {val_loss:.4f}\")\n",
        "print(f\"Validation accuracy: {val_acc:.4f}\")\n"
      ],
      "metadata": {
        "id": "Lxiku3wAmWvx",
        "outputId": "222baa4c-e15b-4f3f-f2ec-dfb1018125a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Lxiku3wAmWvx",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded best model from: asl_best_model.h5\n",
            "Classes (index_to_class): {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z', 26: 'Space', 27: 'Del', 28: 'Nothing'}\n",
            "\u001b[1m488/488\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m150s\u001b[0m 304ms/step - accuracy: 0.9427 - loss: 0.2897\n",
            "Validation loss: 0.6140\n",
            "Validation accuracy: 0.8783\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: Prediction helper for one frame (ROI from camera)\n",
        "\n",
        "def preprocess_frame(frame):\n",
        "    # frame is BGR from OpenCV\n",
        "    img = cv2.resize(frame, (IMG_WIDTH, IMG_HEIGHT))\n",
        "    img = img.astype(\"float32\") / 255.0\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img\n",
        "\n",
        "def predict_label(frame):\n",
        "    \"\"\"\n",
        "    frame: ROI (BGR) with hand sign\n",
        "    returns: label (A-Z, Space, Del, Nothing), confidence\n",
        "    \"\"\"\n",
        "    img = preprocess_frame(frame)\n",
        "    preds = model.predict(img, verbose=0)[0]\n",
        "    idx = np.argmax(preds)\n",
        "    conf = float(preds[idx])\n",
        "    label = index_to_class[idx]\n",
        "    return label, conf\n"
      ],
      "metadata": {
        "id": "eruDom0kmYrp"
      },
      "id": "eruDom0kmYrp",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 9: Live ASL detection using webcam\n",
        "\n",
        "CAPTURE_DURATION = 2.0   # seconds per capture\n",
        "MIN_CONFIDENCE = 0.5     # adjust if needed\n",
        "\n",
        "def run_asl_live():\n",
        "    cap = cv2.VideoCapture(0)  # change to 1 if external cam\n",
        "\n",
        "    if not cap.isOpened():\n",
        "        print(\"Error: Cannot open camera\")\n",
        "        return\n",
        "\n",
        "    current_word = \"\"\n",
        "    sentence = \"\"\n",
        "    last_sentence = \"\"\n",
        "    capturing = False\n",
        "    start_time = None\n",
        "    predictions_window = []\n",
        "    last_action = \"\"\n",
        "\n",
        "    print(\"Controls:\")\n",
        "    print(\"  's'  - start capturing next sign (2 seconds)\")\n",
        "    print(\"  'c'  - clear current word & sentence\")\n",
        "    print(\"  'q'  - quit\")\n",
        "    print(\"\")\n",
        "    print(\"Sign meanings:\")\n",
        "    print(\"  A-Z     -> letters\")\n",
        "    print(\"  Space   -> space (end word / add space)\")\n",
        "    print(\"  Del     -> delete last character\")\n",
        "    print(\"  Nothing -> ENTER (finalize sentence)\")\n",
        "\n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            print(\"Failed to grab frame\")\n",
        "            break\n",
        "\n",
        "        h, w, _ = frame.shape\n",
        "\n",
        "        # Central ROI box\n",
        "        box_size = int(min(h, w) * 0.5)\n",
        "        x1 = w // 2 - box_size // 2\n",
        "        y1 = h // 2 - box_size // 2\n",
        "        x2 = x1 + box_size\n",
        "        y2 = y1 + box_size\n",
        "\n",
        "        roi = frame[y1:y2, x1:x2]\n",
        "\n",
        "        # Capture logic\n",
        "        if capturing:\n",
        "            elapsed = time.time() - start_time\n",
        "            if elapsed <= CAPTURE_DURATION:\n",
        "                if roi.size != 0:\n",
        "                    label, conf = predict_label(roi)\n",
        "                    if conf >= MIN_CONFIDENCE:\n",
        "                        predictions_window.append(label)\n",
        "\n",
        "                cv2.putText(frame, \"CAPTURING...\", (10, 30),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 0, 255), 2)\n",
        "            else:\n",
        "                capturing = False\n",
        "                final_label = None\n",
        "                if predictions_window:\n",
        "                    final_label = max(set(predictions_window),\n",
        "                                      key=predictions_window.count)\n",
        "                predictions_window = []\n",
        "\n",
        "                if final_label is not None:\n",
        "                    if final_label in list(\"ABCDEFGHIJKLMNOPQRSTUVWXYZ\"):\n",
        "                        current_word += final_label\n",
        "                        last_action = f\"Letter: {final_label}\"\n",
        "                        print(f\"Captured letter: {final_label}\")\n",
        "\n",
        "                    elif final_label == \"Space\":\n",
        "                        if current_word:\n",
        "                            sentence += current_word + \" \"\n",
        "                            print(\"Word added to sentence:\", current_word)\n",
        "                            current_word = \"\"\n",
        "                        else:\n",
        "                            sentence += \" \"\n",
        "                        last_action = \"Space (word/space added)\"\n",
        "\n",
        "                    elif final_label == \"Del\":\n",
        "                        if current_word:\n",
        "                            current_word = current_word[:-1]\n",
        "                            last_action = \"Deleted last char in word\"\n",
        "                        else:\n",
        "                            sentence = sentence[:-1]\n",
        "                            last_action = \"Deleted last char in sentence\"\n",
        "                        print(\"Delete action.\")\n",
        "\n",
        "                    elif final_label == \"Nothing\":\n",
        "                        last_sentence = sentence.strip()\n",
        "                        print(\"Sentence ENTERED:\", last_sentence)\n",
        "                        current_word = \"\"\n",
        "                        sentence = \"\"\n",
        "                        last_action = \"Entered sentence (Nothing)\"\n",
        "\n",
        "        # Draw ROI box\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
        "\n",
        "        # Draw text overlays\n",
        "        cv2.putText(frame, f\"Word: {current_word}\", (10, h - 70),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
        "        cv2.putText(frame, f\"Sentence: {sentence}\", (10, h - 40),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
        "        cv2.putText(frame, f\"Last: {last_action}\", (10, h - 10),\n",
        "                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)\n",
        "\n",
        "        if last_sentence:\n",
        "            cv2.putText(frame, f\"Entered: {last_sentence}\",\n",
        "                        (10, 40), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                        0.7, (0, 200, 255), 2)\n",
        "\n",
        "        cv2.imshow(\"ASL Live\", frame)\n",
        "\n",
        "        key = cv2.waitKey(1) & 0xFF\n",
        "\n",
        "        if key == ord('q'):\n",
        "            break\n",
        "\n",
        "        if key == ord('s') and not capturing:\n",
        "            capturing = True\n",
        "            start_time = time.time()\n",
        "            predictions_window = []\n",
        "            last_action = \"Capturing started\"\n",
        "\n",
        "        if key == ord('c'):\n",
        "            current_word = \"\"\n",
        "            sentence = \"\"\n",
        "            last_sentence = \"\"\n",
        "            last_action = \"Cleared all\"\n",
        "            print(\"Cleared word/sentence.\")\n",
        "\n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Final sentence buffer:\", sentence)\n",
        "    print(\"Last entered sentence:\", last_sentence)\n"
      ],
      "metadata": {
        "id": "86IMexB-mcHM"
      },
      "id": "86IMexB-mcHM",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 10: Start live ASL detection\n",
        "\n",
        "run_asl_live()\n"
      ],
      "metadata": {
        "id": "Wkw-AqI9meVG",
        "outputId": "6c0667f6-6be7-431b-d48e-e9af5f8c8cf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Wkw-AqI9meVG",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Cannot open camera\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Neav22u3fFtb"
      },
      "id": "Neav22u3fFtb",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.12"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}